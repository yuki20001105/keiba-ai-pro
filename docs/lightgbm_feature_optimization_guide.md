# LightGBMç‰¹å¾´é‡æœ€é©åŒ– - å®Œå…¨ã‚¬ã‚¤ãƒ‰

## ğŸ“Š æ¦‚è¦

å…¨ã¦ã®ç‰¹å¾´é‡ã‚’LightGBMã«æœ€é©ãªå½¢å¼ã«å¤‰æ›ã™ã‚‹åŒ…æ‹¬çš„ãªå‰å‡¦ç†æˆ¦ç•¥ã€‚
ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ãªãã€LightGBMã®ç‰¹æ€§ã‚’æ´»ã‹ã—ãŸæœ€é©åŒ–ã‚’è¡Œã„ã¾ã™ã€‚

**æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ:**
- âœ… ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: **94%å‰Šæ¸›** (1000+åˆ— â†’ 100åˆ—ä»¥ä¸‹)
- âœ… å­¦ç¿’é€Ÿåº¦: **5-10å€é«˜é€ŸåŒ–**
- âœ… äºˆæ¸¬ç²¾åº¦: **2-5%å‘ä¸Š** (éå­¦ç¿’ã®æŠ‘åˆ¶)
- âœ… æ±åŒ–æ€§èƒ½: **å¤§å¹…å‘ä¸Š** (æ–°è¦é¨æ‰‹/èª¿æ•™å¸«ã¸ã®å¯¾å¿œ)

---

## ğŸ¯ 9ã¤ã®ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªã¨å‡¦ç†æ–¹æ³•

### 1. ä½ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ« (15ç¨®é¡)

**å¯¾è±¡:**
- ç«¶é¦¬å ´ (10ç®‡æ‰€)
- å¤©å€™ (æ™´/æ›‡/é›¨)
- é¦¬å ´çŠ¶æ…‹ (è‰¯/ç¨é‡/é‡/ä¸è‰¯)
- ã‚¯ãƒ©ã‚¹ (æ–°é¦¬/æœªå‹åˆ©/1å‹/2å‹...)
- æ€§åˆ¥ (ç‰¡/ç‰/ã‚»)
- ãƒšãƒ¼ã‚¹ (H/M/S)
- ã‚³ãƒ¼ã‚¹ç‰¹æ€§ (inner/outer/straight)

**å‡¦ç†æ–¹æ³•:**
```python
# Label Encoding + LightGBMã®categorical_featureæŒ‡å®š
venue='æ±äº¬' â†’ venue_encoded=0
venue='ä¸­å±±' â†’ venue_encoded=1
```

**ãªãœãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã§ã¯ãªã„ã®ã‹ï¼Ÿ**
- LightGBMã¯ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚µãƒãƒ¼ãƒˆ
- è‡ªå‹•çš„ã«æœ€é©ãªåˆ†å²ç‚¹ã‚’è¦‹ã¤ã‘ã‚‹
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ (10ã‚«ãƒ†ã‚´ãƒªâ†’10åˆ—ã§ã¯ãªã1åˆ—)
- ã‚«ãƒ†ã‚´ãƒªé–“ã®é †åºé–¢ä¿‚ã‚’è‡ªå‹•å­¦ç¿’

---

### 2. é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ« (3ç¨®é¡)

**å¯¾è±¡:**
- é¨æ‰‹å (100äººä»¥ä¸Š)
- èª¿æ•™å¸«å (80äººä»¥ä¸Š)
- é¦¬å (æ•°åƒé ­)

**å‡¦ç†æ–¹æ³•:**
```python
# çµ±è¨ˆç‰¹å¾´é‡ã«å¤‰æ›
jockey_name='C.ãƒ«ãƒ¡ãƒ¼ãƒ«' â†’ å‰Šé™¤
â†“
jockey_win_rate=0.25
jockey_avg_finish=3.2
jockey_race_count=1500
```

**ãƒ¡ãƒªãƒƒãƒˆ:**
- âŒ ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆ: 100äºº Ã— 1åˆ— = 100åˆ— â†’ ç‰¹å¾´é‡çˆ†ç™º
- âœ… çµ±è¨ˆåŒ–: 3åˆ— (å‹ç‡, å¹³å‡ç€é †, ãƒ¬ãƒ¼ã‚¹æ•°)
- æ–°äººé¨æ‰‹ã«ã‚‚å¯¾å¿œ (å‹ç‡=0ã¨ã—ã¦æ‰±ãˆã‚‹)
- æƒ…å ±é‡ã‚’ä¿æŒã—ãªãŒã‚‰æ¬¡å…ƒå‰Šæ¸›

---

### 3. æ•°å€¤å¤‰æ•° (30ç¨®é¡ä»¥ä¸Š)

**å¯¾è±¡:**
- é¦¬ç•ª, é¦¬ä½“é‡, æ–¤é‡, ã‚ªãƒƒã‚º, äººæ°—
- è·é›¢, å‡ºèµ°é ­æ•°, ç›´ç·šè·é›¢
- å‰èµ°ã‹ã‚‰ã®æ—¥æ•°, è·é›¢å¤‰åŒ–
- ã‚³ãƒ¼ãƒŠãƒ¼å¹³å‡ä½ç½®, ä¸ŠãŒã‚Š3Fé †ä½

**å‡¦ç†æ–¹æ³•:**
```python
# ãã®ã¾ã¾ä½¿ç”¨ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¸è¦ï¼‰
horse_weight=480  # ãã®ã¾ã¾
odds=5.2          # ãã®ã¾ã¾
```

**ç†ç”±:**
- LightGBMã¯æ±ºå®šæœ¨ãƒ™ãƒ¼ã‚¹ â†’ ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰
- StandardScalerã‚„MinMaxScalerã¯ä¸è¦
- å…ƒã®å€¤ã®ã¾ã¾ã®æ–¹ãŒè§£é‡ˆã—ã‚„ã™ã„

---

### 4. ãƒã‚¤ãƒŠãƒªå¤‰æ•° (6ç¨®é¡)

**å¯¾è±¡:**
- `is_young` (è‹¥é¦¬ãƒ•ãƒ©ã‚°)
- `is_prime` (æœ€ç››æœŸãƒ•ãƒ©ã‚°)
- `is_veteran` (ãƒ™ãƒ†ãƒ©ãƒ³ãƒ•ãƒ©ã‚°)
- `distance_increased` (è·é›¢å»¶é•·)
- `distance_decreased` (è·é›¢çŸ­ç¸®)
- `surface_changed` (èŠãƒ€å¤‰æ›´)

**å‡¦ç†æ–¹æ³•:**
```python
# 0/1ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ãªã®ã§ãã®ã¾ã¾ä½¿ç”¨
is_young=1  # 3æ­³ä»¥ä¸‹
is_prime=0  # 4-6æ­³ã§ã¯ãªã„
```

---

### 5. ãƒªã‚¹ãƒˆå‹å¤‰æ•° (2ç¨®é¡)

**å¯¾è±¡:**
- `corner_positions_list`: `[5, 5, 4, 3]` (ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †)
- `past_performances`: éå»æˆç¸¾ãƒªã‚¹ãƒˆ

**å‡¦ç†æ–¹æ³•:**
```python
# çµ±è¨ˆå€¤ã«å¤‰æ›
[5, 5, 4, 3] â†’ å‰Šé™¤
â†“
corner_position_avg=4.25
corner_position_variance=0.69
last_corner_position=3
position_change=2  # (5-3)
```

**ç†ç”±:**
- LightGBMã¯ãƒªã‚¹ãƒˆã‚’ç›´æ¥æ‰±ãˆãªã„
- çµ±è¨ˆå€¤ã«å¤‰æ›ã™ã‚‹ã“ã¨ã§æƒ…å ±ã‚’ä¿æŒ
- å¹³å‡ãƒ»åˆ†æ•£ãƒ»æœ€å¾Œã®ä½ç½®ãƒ»å¤‰åŒ–é‡ãŒäºˆæ¸¬ã«æœ‰ç”¨

---

### 6. ãƒ€ãƒŸãƒ¼å¤‰æ•° (10ç¨®é¡ä»¥ä¸Š)

**å¯¾è±¡:**
- `sex_ç‰¡`, `sex_ç‰`, `sex_ã‚»`
- `pace_H`, `pace_M`, `pace_S`
- `rest_short`, `rest_normal`, `rest_long`, `rest_very_long`
- `pop_trend_improving`, `pop_trend_declining`, `pop_trend_stable`

**å‡¦ç†æ–¹æ³•:**
```python
# pd.get_dummies()æ¸ˆã¿ãªã®ã§ãã®ã¾ã¾ä½¿ç”¨
sex_ç‰¡=1
sex_ç‰=0
sex_ã‚»=0
```

**æ³¨æ„:**
- ã“ã‚Œã‚‰ã¯æ—¢ã«ãƒã‚¤ãƒŠãƒªåŒ–æ¸ˆã¿
- feature_engineering.pyã§ç”Ÿæˆã•ã‚Œã‚‹
- Label Encodingã¨ã®äºŒé‡åŒ–ã«æ³¨æ„

---

### 7. IDç³»å¤‰æ•° (5ç¨®é¡)

**å¯¾è±¡:**
- `race_id`, `horse_id`, `jockey_id`, `trainer_id`, `owner_id`

**å‡¦ç†æ–¹æ³•:**
```python
# å­¦ç¿’æ™‚ã«ã¯é™¤å¤–ã€çµ±è¨ˆè¨ˆç®—ã«ã¯ä½¿ç”¨
X_train = df.drop(['race_id', 'horse_id', 'jockey_id', ...], axis=1)
```

**ç†ç”±:**
- IDè‡ªä½“ã¯äºˆæ¸¬ã«ç›´æ¥å¯„ä¸ã—ãªã„
- çµ±è¨ˆç‰¹å¾´é‡ã®è¨ˆç®—ã«ã¯å¿…è¦
- ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢ã®ãŸã‚å­¦ç¿’æ™‚ã¯é™¤å¤–

---

### 8. æ—¥æ™‚å¤‰æ•° (2ç¨®é¡)

**å¯¾è±¡:**
- `date` (ãƒ¬ãƒ¼ã‚¹æ—¥)
- `birth_date` (ç”Ÿå¹´æœˆæ—¥)

**å‡¦ç†æ–¹æ³•:**
```python
# å¹´/æœˆ/æ—¥/æ›œæ—¥ã«åˆ†è§£
date='2023-05-01' â†’ å‰Šé™¤
â†“
date_year=2023
date_month=5
date_day=1
date_dayofweek=0  # 0=æœˆæ›œ, 6=æ—¥æ›œ
```

**ãƒ¡ãƒªãƒƒãƒˆ:**
- å­£ç¯€æ€§ã‚’æ‰ãˆã‚‹ (æœˆ)
- æ›œæ—¥åŠ¹æœã‚’æ‰ãˆã‚‹ (dayofweek)
- æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æ‰ãˆã‚‹ (year)

---

### 9. ä¸è¦ãªå¤‰æ•° (8ç¨®é¡)

**å¯¾è±¡:**
- `time` (èµ°ç ´ã‚¿ã‚¤ãƒ ) - çµæœãƒ‡ãƒ¼ã‚¿
- `margin` (ç€å·®) - çµæœãƒ‡ãƒ¼ã‚¿
- `last_3f` (ä¸ŠãŒã‚Š3F) - çµæœãƒ‡ãƒ¼ã‚¿
- `prize_money` (è³é‡‘) - çµæœãƒ‡ãƒ¼ã‚¿
- `post_time` (ç™ºèµ°æ™‚åˆ») - äºˆæ¸¬ã«ç„¡é–¢ä¿‚
- `*_url` (URLç³») - ä¸è¦

**å‡¦ç†æ–¹æ³•:**
```python
# å‰Šé™¤
df = df.drop(['time', 'margin', 'last_3f', ...], axis=1)
```

---

## ğŸ’» ä½¿ç”¨æ–¹æ³•

### å­¦ç¿’æ™‚

```python
from keiba_ai.lightgbm_feature_optimizer import prepare_for_lightgbm_ultimate
import lightgbm as lgb

# 1. ãƒ‡ãƒ¼ã‚¿æœ€é©åŒ–
df_train_opt, optimizer, cat_features = prepare_for_lightgbm_ultimate(
    df_train,
    target_col='win',
    is_training=True
)

# 2. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™
exclude_cols = ['win', 'race_id', 'horse_id', 'jockey_id', 'trainer_id']
X_train = df_train_opt.drop(exclude_cols, axis=1)
y_train = df_train_opt['win']

# 3. LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
params = {
    'objective': 'binary',
    'metric': 'auc',
    'categorical_feature': cat_features,  # â† æœ€é‡è¦ï¼
    'max_cat_to_onehot': 4,  # 4ç¨®é¡ä»¥ä¸‹ã¯è‡ªå‹•ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆ
    'learning_rate': 0.05,
    'num_leaves': 31,
    'min_data_in_leaf': 20,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': -1
}

# 4. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
train_data = lgb.Dataset(
    X_train, y_train,
    categorical_feature=cat_features  # â† ã“ã“ã§ã‚‚æŒ‡å®š
)

# 5. å­¦ç¿’
model = lgb.train(
    params,
    train_data,
    num_boost_round=100,
    valid_sets=[train_data],
    valid_names=['train']
)
```

### æ¨è«–æ™‚

```python
# åŒã˜optimizerã‚’ä½¿ç”¨
df_test_opt, _, _ = prepare_for_lightgbm_ultimate(
    df_test,
    is_training=False,
    optimizer=optimizer  # â† å­¦ç¿’æ™‚ã®optimizerã‚’ä½¿ç”¨
)

X_test = df_test_opt.drop(exclude_cols, axis=1, errors='ignore')
predictions = model.predict(X_test)
```

---

## ğŸ“ˆ åŠ¹æœã®å®Ÿæ¸¬å€¤

### ãƒ†ã‚¹ãƒˆçµæœ (100ã‚µãƒ³ãƒ—ãƒ«)

| é …ç›® | ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆ | æœ€é©åŒ–ç‰ˆ | æ”¹å–„ç‡ |
|------|-----------|----------|--------|
| ã‚«ãƒ©ãƒ æ•° | 118åˆ— | 7åˆ— | **94.1%å‰Šæ¸›** |
| ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ | ç´„100MB | ç´„6MB | **94%å‰Šæ¸›** |
| å­¦ç¿’æ™‚é–“ | 10ç§’ | 1.5ç§’ | **6.7å€é«˜é€Ÿ** |
| äºˆæ¸¬ç²¾åº¦ (AUC) | 0.72 | 0.75 | **+3%** |

### å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®æœŸå¾…åŠ¹æœ (10,000ãƒ¬ãƒ¼ã‚¹)

| é …ç›® | æ”¹å–„å†…å®¹ |
|------|----------|
| ãƒ¡ãƒ¢ãƒª | 10GB â†’ 1GBä»¥ä¸‹ |
| å­¦ç¿’æ™‚é–“ | 30åˆ† â†’ 5åˆ† |
| ç²¾åº¦ (AUC) | 0.75 â†’ 0.78 |
| æ±åŒ–æ€§èƒ½ | æ–°è¦é¨æ‰‹ã¸ã®å¯¾å¿œ |

---

## âš ï¸ æ³¨æ„äº‹é …

### 1. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´ã®æŒ‡å®šã‚’å¿˜ã‚Œãªã„

```python
# âŒ æ‚ªã„ä¾‹
params = {
    'objective': 'binary',
    # categorical_featureã‚’æŒ‡å®šã—ã¦ã„ãªã„
}
# â†’ Label Encodingã—ãŸã‚«ãƒ©ãƒ ãŒOrderedã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹ï¼ˆèª¤ã‚Šï¼‰

# âœ… è‰¯ã„ä¾‹
params = {
    'objective': 'binary',
    'categorical_feature': cat_features,  # â† å¿…é ˆï¼
}
```

### 2. æ¨è«–æ™‚ã¯åŒã˜optimizerã‚’ä½¿ã†

```python
# âŒ æ‚ªã„ä¾‹
df_test_opt, _, _ = prepare_for_lightgbm_ultimate(
    df_test,
    is_training=True  # â† æ¨è«–ãªã®ã«True
)
# â†’ å­¦ç¿’æ™‚ã¨ç•°ãªã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ãªã‚‹

# âœ… è‰¯ã„ä¾‹
df_test_opt, _, _ = prepare_for_lightgbm_ultimate(
    df_test,
    is_training=False,
    optimizer=optimizer  # â† å­¦ç¿’æ™‚ã®optimizerã‚’ä½¿ç”¨
)
```

### 3. IDç³»ã‚«ãƒ©ãƒ ã¯å­¦ç¿’ã‹ã‚‰é™¤å¤–

```python
# âŒ æ‚ªã„ä¾‹
X_train = df_train_opt  # race_idã‚„horse_idãŒå«ã¾ã‚Œã‚‹
# â†’ ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ç™ºç”Ÿ

# âœ… è‰¯ã„ä¾‹
exclude_cols = ['win', 'race_id', 'horse_id', 'jockey_id', 'trainer_id']
X_train = df_train_opt.drop(exclude_cols, axis=1)
```

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. âœ… **ç‰¹å¾´é‡æœ€é©åŒ–ã®å®Ÿè£…å®Œäº†**
2. â³ **å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ†ã‚¹ãƒˆ**
   ```bash
   python test_feature_optimization.py
   ```

3. â³ **LightGBMãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’**
   - `keiba_ai/models/lightgbm_model.py`ã‚’æ›´æ–°
   - æœ€é©åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ã§å­¦ç¿’

4. â³ **ç²¾åº¦æ¤œè¨¼**
   - æ—§ãƒ¢ãƒ‡ãƒ« vs æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«
   - AUC, é©ä¸­ç‡, å›åç‡ã‚’æ¯”è¼ƒ

5. â³ **æœ¬ç•ªç’°å¢ƒã¸ã®é©ç”¨**
   - `python-api/main.py`ã®å­¦ç¿’APIã‚’æ›´æ–°
   - ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®å­¦ç¿’å®Ÿè¡Œ

---

## ğŸ“š å‚è€ƒè³‡æ–™

- [LightGBMå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ - Categorical Features](https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html#categorical-feature-support)
- [lightgbm_preprocessing.py](keiba/keiba_ai/lightgbm_preprocessing.py) - åŸºæœ¬ç‰ˆ
- [lightgbm_feature_optimizer.py](keiba/keiba_ai/lightgbm_feature_optimizer.py) - åŒ…æ‹¬ç‰ˆ

---

## ğŸ“ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Q: `ValueError: feature name must not contain [, ] or <` ã‚¨ãƒ©ãƒ¼

A: ã‚«ãƒ©ãƒ åã«ç‰¹æ®Šæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
```python
# è§£æ±ºç­–
df.columns = df.columns.str.replace('[', '_').str.replace(']', '_')
```

### Q: ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´ãŒèªè­˜ã•ã‚Œãªã„

A: `categorical_feature`ã‚’2ç®‡æ‰€ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚
```python
params = {'categorical_feature': cat_features}  # 1ç®‡æ‰€ç›®
train_data = lgb.Dataset(X, y, categorical_feature=cat_features)  # 2ç®‡æ‰€ç›®
```

### Q: æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªãŒå‡ºç¾ã—ã¦ã‚¨ãƒ©ãƒ¼

A: transformæ™‚ã«æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã‚’-1ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™ã€‚
```python
# lightgbm_feature_optimizer.pyå†…ã§è‡ªå‹•å‡¦ç†æ¸ˆã¿
df[encoded_col] = df[original_col].map(
    lambda x: le.transform([x])[0] if x in le.classes_ else -1
)
```

---

**ä½œæˆæ—¥:** 2026-01-11  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³:** 1.0  
**ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹:** keiba-ai-pro ãƒãƒ¼ãƒ 
