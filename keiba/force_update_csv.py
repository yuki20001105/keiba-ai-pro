"""å¼·åˆ¶çš„ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ï¼ˆãƒ†ã‚¹ãƒˆç‰ˆï¼šæœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"""
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

import pandas as pd
import requests
import time
from keiba_ai.netkeiba.parsers import parse_result_table

csv_dir = Path("data/netkeiba/results_by_race")
csv_files = list(csv_dir.glob("*.csv"))[:10]  # ãƒ†ã‚¹ãƒˆç”¨ã«æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿

print(f"ğŸ“ {len(csv_files)} CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¼·åˆ¶æ›´æ–°")
print("=" * 60)

session = requests.Session()
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
}

updated = 0
failed = 0

for i, csv_file in enumerate(csv_files, 1):
    race_id = csv_file.stem
    print(f"\n[{i}/{len(csv_files)}] {race_id}")
    
    # HTMLã‹ã‚‰å†å–å¾—ã—ã¦ãƒ‘ãƒ¼ã‚¹
    try:
        url = f"https://race.netkeiba.com/race/result.html?race_id={race_id}"
        response = session.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        response.encoding = response.apparent_encoding or 'EUC-JP'
        
        df_new = parse_result_table(response.text)
        df_new["race_id"] = race_id
        
        horse_id_count = df_new['horse_id'].notna().sum() if 'horse_id' in df_new.columns else 0
        finish_count = df_new['finish'].notna().sum() if 'finish' in df_new.columns else 0
        print(f"  ãƒ‡ãƒ¼ã‚¿: {len(df_new)}é ­, horse_id={horse_id_count}, finish={finish_count}")
        
        # CSVã‚’ä¸Šæ›¸ãä¿å­˜
        df_new.to_csv(csv_file, index=False, encoding='utf-8-sig')
        updated += 1
        print(f"  â†’ âœ… æ›´æ–°å®Œäº†")
        
        time.sleep(0.5)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        
    except Exception as e:
        failed += 1
        print(f"  â†’ âŒ å¤±æ•—: {e}")

print()
print("=" * 60)
print("å¼·åˆ¶æ›´æ–°å®Œäº†")
print("=" * 60)
print(f"ã€çµæœã€‘")
print(f"  âœ… æ›´æ–°: {updated} ãƒ•ã‚¡ã‚¤ãƒ«")
print(f"  âŒ å¤±æ•—: {failed} ãƒ•ã‚¡ã‚¤ãƒ«")
