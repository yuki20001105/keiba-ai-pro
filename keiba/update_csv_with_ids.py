"""æ—¢å­˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã«horse_idç­‰ã‚’è¿½åŠ """
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

import pandas as pd
import requests
from keiba_ai.netkeiba.parsers import parse_result_table

csv_dir = Path("data/netkeiba/results_by_race")
csv_files = list(csv_dir.glob("*.csv"))

print(f"ğŸ“ {len(csv_files)} CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†")
print("=" * 60)

session = requests.Session()
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
}

updated = 0
skipped = 0
failed = 0

for i, csv_file in enumerate(csv_files, 1):
    race_id = csv_file.stem
    
    # é€²æ—è¡¨ç¤º
    if i % 100 == 0 or i == len(csv_files):
        print(f"  é€²è¡Œä¸­... {i}/{len(csv_files)} ({updated} æ›´æ–° / {skipped} ã‚¹ã‚­ãƒƒãƒ— / {failed} å¤±æ•—)")
    
    # æ—¢å­˜CSVã‚’èª­ã¿è¾¼ã¿
    df_old = pd.read_csv(csv_file, encoding='utf-8-sig')
    
    # horse_idãŒã™ã§ã«å­˜åœ¨ã—ã¦æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
    if 'horse_id' in df_old.columns and df_old['horse_id'].notna().any():
        skipped += 1
        continue
    
    # HTMLã‹ã‚‰å†å–å¾—ã—ã¦ãƒ‘ãƒ¼ã‚¹
    try:
        url = f"https://race.netkeiba.com/race/result.html?race_id={race_id}"
        response = session.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        response.encoding = response.apparent_encoding or 'EUC-JP'
        
        df_new = parse_result_table(response.text)
        df_new["race_id"] = race_id
        
        # CSVã‚’ä¸Šæ›¸ãä¿å­˜
        df_new.to_csv(csv_file, index=False, encoding='utf-8-sig')
        updated += 1
        
    except Exception as e:
        failed += 1
        if failed <= 5:  # æœ€åˆã®5å€‹ã ã‘ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
            print(f"    âŒ {race_id}: {e}")

print()
print("=" * 60)
print("CSVæ›´æ–°å®Œäº†")
print("=" * 60)
print(f"ã€çµæœã€‘")
print(f"  âœ… æ›´æ–°: {updated} ãƒ•ã‚¡ã‚¤ãƒ«")
print(f"  â­  ã‚¹ã‚­ãƒƒãƒ—: {skipped} ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ—¢ã«horse_idæœ‰ï¼‰")
print(f"  âŒ å¤±æ•—: {failed} ãƒ•ã‚¡ã‚¤ãƒ«")
